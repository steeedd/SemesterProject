{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine, inspect\n",
    "from huggingface_hub import InferenceClient\n",
    "from google.colab import userdata\n",
    "\n",
    "my_token = userdata.get('HF_TOKEN')\n",
    "client = InferenceClient(model=\"Qwen/Qwen3-8B\", token=my_token) \n",
    "\n",
    "def clean_sql_query(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    match = re.search(r\"```(?:sql)?\\s*(.*?)\\s*```\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    text_upper = text.upper()\n",
    "    keywords = [\"SELECT \", \"WITH \", \"VALUES \", \"INSERT \", \"UPDATE \", \"DELETE \"]\n",
    "    start_index = -1\n",
    "    for kw in keywords:\n",
    "        idx = text_upper.find(kw)\n",
    "        if idx != -1 and (start_index == -1 or idx < start_index):\n",
    "            start_index = idx\n",
    "    if start_index != -1:\n",
    "        raw_sql = text[start_index:]\n",
    "        last_semicolon = raw_sql.rfind(\";\")\n",
    "        if last_semicolon != -1:\n",
    "            raw_sql = raw_sql[:last_semicolon + 1]\n",
    "        return raw_sql.strip()\n",
    "    return text.strip()\n",
    "\n",
    "def get_schema_string(inspector):\n",
    "    schema_str = \"Database Schema:\\n\"\n",
    "    try:\n",
    "        for table in inspector.get_table_names():\n",
    "            schema_str += f\"Table: {table}\\n\"\n",
    "            columns = inspector.get_columns(table)\n",
    "            for col in columns:\n",
    "                schema_str += f\"  - {col['name']} ({col['type']})\\n\"   \n",
    "    except:\n",
    "        return \"\"\n",
    "    return schema_str\n",
    "\n",
    "def run_query(db_path, query):\n",
    "  conn = sqlite3.connect(db_path)\n",
    "  try:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "\n",
    "    # Flatten results and convert to list of strings\n",
    "    return [row[0] for row in rows], True\n",
    "  except:\n",
    "    return [], False\n",
    "\n",
    "def compute_execution_accuracy(gt_results, predict_results):\n",
    "    num_correct = 0\n",
    "    num_queries = len(gt_results)\n",
    "    mismatch_idx = []\n",
    "\n",
    "    for i, result in enumerate(gt_results):\n",
    "        if set(result['results']) == set(predict_results[i]['results']):\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            mismatch_idx.append(i)\n",
    "    acc = num_correct / num_queries\n",
    "    return acc\n",
    "\n",
    "def process_database(db_name):\n",
    "    print(f\"\\n{'='*40}\\nProcessing Database: {db_name}\\n{'='*40}\")\n",
    "    path_json = f\"dataset/{db_name}/{db_name}.json\"\n",
    "    path_sql = f\"dataset/{db_name}/{db_name}.sqlite\"\n",
    "    if not os.path.exists(path_json) or not os.path.exists(path_sql):\n",
    "        print(f\"Skipping {db_name}: Missing files.\")\n",
    "        return []\n",
    "\n",
    "    with open(path_json, \"r\") as f:\n",
    "        questions = json.load(f)\n",
    "\n",
    "    q_ids = {}\n",
    "    if os.path.exists(\"golds.json\"):\n",
    "        with open(\"golds.json\", 'r') as v:\n",
    "            golds_list = json.load(v)\n",
    "            q_ids = {g[\"question_id\"]: g for g in golds_list}\n",
    "\n",
    "    db_uri = f\"sqlite:///{path_sql}\"\n",
    "    engine = create_engine(db_uri)\n",
    "    inspector = inspect(engine)\n",
    "    schema_text = get_schema_string(inspector)\n",
    "\n",
    "    traces = []\n",
    "    for i, q in enumerate(questions):\n",
    "        q_id = q.get(\"question_id\")\n",
    "        question_text = q.get(\"questions\", \"\")\n",
    "        evidence = q.get(\"evidence\", \"\")\n",
    "        difficulty = q.get(\"difficulty\", \"unknown\")\n",
    "        gt_entry = q_ids.get(q_id, {})\n",
    "        gt_query = gt_entry.get(\"target_sql\", \"\")\n",
    "        if gt_query is None:\n",
    "            gt_query = \"\"\n",
    "\n",
    "        print(f\"--- Q{i+1} ({db_name}) ---\")\n",
    "\n",
    "        system_prompt = \"\"\"You are an expert Data Scientist specialized in Text-to-SQL tasks.\n",
    "You will be given a task to solve as best you can.\n",
    "Task: Convert the user's question into a valid SQL query based on the schema.\n",
    "Instructions:\n",
    "1. Output ONLY the SQL query.\n",
    "2. Do not explain your answer.\n",
    "\"\"\"\n",
    "        user_input = f\"{schema_text}\\n\\nQuestion: {evidence} {question_text}\"\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "\n",
    "        error_count = 0\n",
    "        raw_output = \"\"\n",
    "        try:\n",
    "            response = client.chat_completion(messages=messages, max_tokens=4096, temperature=0.01)\n",
    "            content = response.choices[0].message.content\n",
    "            raw_output = content if content else \"\"\n",
    "        except Exception as e:\n",
    "            raw_output = f\"ERROR_API_FAILED: {str(e)}\"\n",
    "            print(f\"Failed to get response for Q{i+1}\")\n",
    "            error_count = 1\n",
    "\n",
    "        pred_query = raw_output if \"ERROR_API_FAILED\" in raw_output else clean_sql_query(raw_output)\n",
    "\n",
    "        exec_acc = 0\n",
    "        if error_count == 0 and gt_query and not pred_query.startswith(\"ERROR\"):\n",
    "            rows_gt, _ = run_query(path_sql, gt_query)\n",
    "            rows_pred, is_valid_sql = run_query(path_sql, pred_query)\n",
    "            if is_valid_sql:\n",
    "                gt_res = [{\"results\": rows_gt}]\n",
    "                pred_res = [{\"results\": rows_pred}]\n",
    "                exec_acc = compute_execution_accuracy(gt_res, pred_res)\n",
    "\n",
    "        trace_entry = {\n",
    "            \"question_id\": q_id,\n",
    "            \"difficulty\": difficulty,\n",
    "            \"pred_query\": pred_query,\n",
    "            \"target_query\": gt_query,\n",
    "            \"execution_accuracy\": int(exec_acc),\n",
    "        }\n",
    "        traces.append(trace_entry)\n",
    "\n",
    "        display = pred_query[:60] + \"...\" if len(pred_query) > 60 else pred_query\n",
    "        print(f\"SQL: {display}\\nAcc: {exec_acc}\")\n",
    "\n",
    "    output_dir = \"traces_baseline\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(f\"{output_dir}/{db_name}.json\", \"w\") as f:\n",
    "        json.dump(traces, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    return traces\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_root = \"dataset\"\n",
    "    master_traces = []\n",
    "\n",
    "    if os.path.exists(dataset_root):\n",
    "        all_dbs = [d for d in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, d))]\n",
    "        for db in all_dbs:\n",
    "            try:\n",
    "                db_traces = process_database(db)\n",
    "                master_traces.extend(db_traces)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {db}: {e}\")\n",
    "                continue\n",
    "\n",
    "        with open(\"traces_baseline/traces_baseline.json\", \"w\") as f:\n",
    "            json.dump(master_traces, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"Completed. Saved {len(master_traces)} traces.\")\n",
    "    else:\n",
    "        print(\"Dataset folder not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
